{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Translation using Seq2Seq models with Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will be demostration English to spanish machine translation task using a LSTM based seq2seq model with Attention Mechanism. I will be demostration English to spanish machine translation task using a LSTM based seq2seq model with Attention Mechanism. The whole model can be thought of as a seq2seq translation model with an Attention layer between the decoder and encoder.\n",
    "\n",
    "So, What is Attention and Why do we need it in the first place?\n",
    "\n",
    "The answer to this question itself is another quetion, Why do we need LSTM ?\n",
    "\n",
    "LSTM helps to mitigate the vanishing gradient problem and thus enabling the model to learn very long seqences, but how long? They also have a limit right? This is where attention comes in.\n",
    "\n",
    "So, coming back to the encoder decoder model. Notice that we have only used the finial state from the encoder in the previous model assuming that the model has successfuly encoded the information regarding the entire seqence and so taking the final hidden state is sufficient. Although this techniqe works well in several cases, as I said before, they also have limitiations. The biggest limitation is the seqence length itself. Consider the example of a machine translation task:\n",
    "\n",
    "How would a human translator translate a text? Would he/she take the entire input all at once or translate it part by part giving attention to the relevent part one by one? Naturally the second option right? The idea of attention mechanism is exactly this. For each output seqence, consider only the relevent input seqence, It's as simple as this.\n",
    "\n",
    "And how would we do this? Simply use a softmax layer in between encoder and decoder. That is, we add another neural network, not a recurrent one but a simple dense layer or multiple dense layers between encoder and decoder. The final layer of this neural network must be a softmax layer, that' it. We are using a neural network so that the whold model is end to end differentible and we can train the whole model as one using back propagation.\n",
    "\n",
    "The inputs to this attention layer will be a concatenation of the t-1 state from the decoder and each hidden state of the encoder. i.e, we take a copy of a single seqence from the decoder and repeatedly concatenate it with each seqence from the encoder and feed it to the attention layer. This must be reapeated for the entire decoder seqences. The outputs from the attention layer will contain the attention weights. Next, we take a dot product between these attention weigts and each encoder hidden states and finally a context vector is produced by taking a weighted sum of this dot product operation. If we are using teacher forcing, this context vector is again concatenated with the inputs and fed into the decoder LSTM.\n",
    "\n",
    "To summerize, the input to decoder LSTM in this case will be the Context vector and not the final hidden state from the encoder LSTM. Therefore, we will initalize the first hidden and cell states seperately so that we will have control of these states since we need them for our genrerative model. Also, here, will return the entire seqence from the encoder LSTM since they are needed to calculate the attention weights.\n",
    "\n",
    "Link to download the pre-trained word embeddings: http://nlp.stanford.edu/data/glove.6B.zip\n",
    "\n",
    "Link to download the translation training texts: http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "daVYW8TyODZJ",
    "outputId": "6643abf1-6af9-446f-bc4a-1022bb407ee4"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  %tensorflow_version 2.x  # Colab only.\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "f3wnlyqCOQ7y",
    "outputId": "d4f53b07-c37b-4ce1-9035-1c14fb1bf9fe"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yK3iHTLmOQ_N",
    "outputId": "4d517bc4-91a6-4fd7-c358-25be44856c8b"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding, \\\n",
    "  Bidirectional, RepeatVector, Concatenate, Activation, Dot, Lambda\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M3lRWE1iORCL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hb7W__fORFS"
   },
   "outputs": [],
   "source": [
    "# config\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 18\n",
    "LATENT_DIM = 400\n",
    "LATENT_DIM_DECODER = 400 # idea: make it different to ensure things all fit together properly!\n",
    "NUM_SAMPLES = 20000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "DATA_PATH = '/content/drive/My Drive/Dataset/spa-eng/spa.txt'\n",
    "WORD2VEC_PATH = '/content/drive/My Drive/Dataset/WordVectors/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Over time\n",
    "\n",
    "We must take the attention softmax over the time axis, which is the 2nd axis. In Keras, by default the softmax is taken along the last axis. Therefore, we will use a custome function to perform this operation.\n",
    "\n",
    "Note: In the lastest version of Keras we can specify this by passing in the axis argument while calling the softmax function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_over_time(x):\n",
    "  assert(K.ndim(x) > 2)\n",
    "  e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
    "  s = K.sum(e, axis=1, keepdims=True)\n",
    "  return e / s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2vfMsX88ORIT"
   },
   "outputs": [],
   "source": [
    "# Where we will store the data\n",
    "input_texts = [] # sentence in original language\n",
    "target_texts = [] # sentence in target language\n",
    "target_texts_inputs = [] # sentence in target language offset by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BAFkVLaORk3j",
    "outputId": "feaed24d-6395-4812-a58b-9b69ef3f1729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 20000\n"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "# download the data at: http://www.manythings.org/anki/\n",
    "t = 0\n",
    "for line in open(\"spa-eng/spa.txt\",encoding=\"utf-8\"):\n",
    "  # only keep a limited number of samples\n",
    "  t += 1\n",
    "  if t > NUM_SAMPLES:\n",
    "    break\n",
    "\n",
    "  # input and target are separated by tab\n",
    "  if '\\t' not in line:\n",
    "    continue\n",
    "\n",
    "  # split up the input and translation\n",
    "  input_text, translation, *rest = line.rstrip().split('\\t')\n",
    "\n",
    "  # make the target input and output\n",
    "  # recall we'll be using teacher forcing\n",
    "  target_text = translation + ' <eos>'\n",
    "  target_text_input = '<sos> ' + translation\n",
    "\n",
    "  input_texts.append(input_text)\n",
    "  target_texts.append(target_text)\n",
    "  target_texts_inputs.append(target_text_input)\n",
    "print(\"num samples:\", len(input_texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4X_PaB99Rk6X"
   },
   "outputs": [],
   "source": [
    "# tokenize the inputs\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7G2iVCWLRk9F",
    "outputId": "484a6079-c570-4e03-981c-439287f58c1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3767 unique input tokens.\n"
     ]
    }
   ],
   "source": [
    "# get the word to index mapping for input language\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbgwuE8bRk_7"
   },
   "outputs": [],
   "source": [
    "# determine maximum length input sequence\n",
    "max_len_input = max(len(s) for s in input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbDYccTTRlDE"
   },
   "outputs": [],
   "source": [
    "# tokenize the outputs\n",
    "# don't filter out special characters\n",
    "# otherwise <sos> and <eos> won't appear\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g7aGOlhIRlId",
    "outputId": "2bd55b66-1285-43a1-ac2c-98a4f81eb03c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10516 unique output tokens.\n"
     ]
    }
   ],
   "source": [
    "# get the word to index mapping for output language\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('Found %s unique output tokens.' % len(word2idx_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kpc3RgX7RlNW"
   },
   "outputs": [],
   "source": [
    "# store number of output words for later\n",
    "# remember to add 1 since indexing starts at 1\n",
    "num_words_output = len(word2idx_outputs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sRlYhkETRlGZ"
   },
   "outputs": [],
   "source": [
    "# determine maximum length output sequence\n",
    "max_len_target = max(len(s) for s in target_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "3uYQUHNCTZx1",
    "outputId": "4c7738aa-d6b5-4463-ca48-b2fba7e92f35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_data.shape: (20000, 6)\n",
      "encoder_data[0]: [ 0  0  0  0  0 22]\n",
      "decoder_data[0]: [   2 2851    0    0    0    0    0    0    0    0    0    0    0]\n",
      "decoder_data.shape: (20000, 13)\n"
     ]
    }
   ],
   "source": [
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_data.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_data[0]:\", encoder_inputs[0])\n",
    "\n",
    "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
    "print(\"decoder_data[0]:\", decoder_inputs[0])\n",
    "print(\"decoder_data.shape:\", decoder_inputs.shape)\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "epTJSTluUO7U"
   },
   "outputs": [],
   "source": [
    "#with io.open('/content/gdrive/Place/Of/Your/Choice/glove.6B.300d.txt', encoding='utf8') as f:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Glove Vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "JHFsvr7HTZ0r",
    "outputId": "66404fa9-becc-4456-813a-d488dc8629ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# store all the pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(\"../Toxic-Comment-Classification/WordVectors/glove.6B.100d.txt\" , encoding='utf8') as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DDjN3Q7_TZ3n",
    "outputId": "59d13b14-1044-4965-c6a2-12cefbbf34ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "  if i < MAX_NUM_WORDS:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model\n",
    "\n",
    "#### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ashVQNrTZ6r"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0509 22:54:01.162398 33168 deprecation_wrapper.py:119] From C:\\Users\\Parth\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=max_len_input,\n",
    "  # trainable=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sH78-vIFTaA1"
   },
   "outputs": [],
   "source": [
    "# create targets, since we cannot use sparse\n",
    "# categorical cross entropy when we have sequences\n",
    "decoder_targets_one_hot = np.zeros(\n",
    "  (\n",
    "    len(input_texts),\n",
    "    max_len_target,\n",
    "    num_words_output\n",
    "  ),\n",
    "  dtype='float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H554CdsmVoMj"
   },
   "outputs": [],
   "source": [
    "# assign the values\n",
    "for i, d in enumerate(decoder_targets):\n",
    "  for t, word in enumerate(d):\n",
    "    if word > 0:\n",
    "      decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sXKbrVIiVuIr"
   },
   "source": [
    "#### Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-wLTKquVoSZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0509 22:54:01.449020 33168 deprecation_wrapper.py:119] From C:\\Users\\Parth\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0509 22:54:01.461252 33168 deprecation_wrapper.py:119] From C:\\Users\\Parth\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0509 22:54:01.474920 33168 deprecation_wrapper.py:119] From C:\\Users\\Parth\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0509 22:54:01.474920 33168 deprecation_wrapper.py:119] From C:\\Users\\Parth\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up the encoder - simple!\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = Bidirectional(LSTM(\n",
    "  LATENT_DIM,\n",
    "  return_sequences=True,\n",
    "  # dropout=0.5 # dropout not available on gpu\n",
    "))\n",
    "encoder_outputs = encoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Decoder\n",
    "The decoder and Attention mechanism is tightly coupled as if they both form a single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIJr-4M_VoXv"
   },
   "outputs": [],
   "source": [
    "# Set up the decoder - not so simple\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFh73ryoVoWD"
   },
   "outputs": [],
   "source": [
    "# this word embedding will not use pre-trained vectors\n",
    "# although you could\n",
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMXA3uNCV4Fa"
   },
   "source": [
    "#### The Attention Mechanism\n",
    "###### Setting up attention layers\n",
    "The attention layers must be global because they must be used again and again for the entire length of output seqence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BEYPtss_VoPy"
   },
   "outputs": [],
   "source": [
    "# Attention layers need to be global because\n",
    "# they will be repeated Ty times at the decoder\n",
    "attn_repeat_layer = RepeatVector(max_len_input)\n",
    "attn_concat_layer = Concatenate(axis=-1)\n",
    "attn_dense1 = Dense(10, activation='tanh')\n",
    "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
    "attn_dot = Dot(axes=1) # to perform the weighted sum of alpha[t] * h[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "63LrcmbiTaEH"
   },
   "outputs": [],
   "source": [
    "def one_step_attention(h, st_1):\n",
    "  # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
    "  # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
    " \n",
    "  # copy s(t-1) Tx times\n",
    "  # now shape = (Tx, LATENT_DIM_DECODER)\n",
    "  st_1 = attn_repeat_layer(st_1)\n",
    "\n",
    "  # Concatenate all h(t)'s with s(t-1)\n",
    "  # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
    "  x = attn_concat_layer([h, st_1])\n",
    "\n",
    "  # Neural net first layer\n",
    "  x = attn_dense1(x)\n",
    "\n",
    "  # Neural net second layer with special softmax over time\n",
    "  alphas = attn_dense2(x)\n",
    "\n",
    "  # \"Dot\" the alphas and the h's\n",
    "  # Remember a.dot(b) = sum over a[t] * b[t]\n",
    "  context = attn_dot([alphas, h])\n",
    "\n",
    "  return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BWepg019TZ_K"
   },
   "outputs": [],
   "source": [
    "# define the rest of the decoder (after attention)\n",
    "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pk2FZQcUWAhK"
   },
   "outputs": [],
   "source": [
    "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
    "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
    "context_last_word_concat_layer = Concatenate(axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the usual seq2seq model the output is not directly taken from the decoder LSTM, here we must loop through the entire output seqences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r5IZE_32WAkI"
   },
   "outputs": [],
   "source": [
    "# s, c will be re-assigned in each iteration of the loop\n",
    "s = initial_s\n",
    "c = initial_c\n",
    "\n",
    "# collect outputs in a list at first\n",
    "outputs = []\n",
    "for t in range(max_len_target): # Ty times\n",
    "  # get the context using attention\n",
    "  context = one_step_attention(encoder_outputs, s)\n",
    "\n",
    "  # we need a different layer for each time step\n",
    "  selector = Lambda(lambda x: x[:, t:t+1])\n",
    "  xt = selector(decoder_inputs_x)\n",
    "  \n",
    "  # combine \n",
    "  decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "\n",
    "  # pass the combined [context, last word] into the LSTM\n",
    "  # along with [s, c]\n",
    "  # get the new [s, c] and output\n",
    "  o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
    "\n",
    "  # final dense layer to get next word prediction\n",
    "  decoder_outputs = decoder_dense(o)\n",
    "  outputs.append(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we looped through the entire output seqence, our final output will be of shape (output_seq, batch_size, output_vocab). This is not what we want, threfore we must transpose the output vector into the shape (batch_size,output_seq,output_vocab).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zp4bxG8DWAnC"
   },
   "outputs": [],
   "source": [
    "# 'outputs' is now a list of length Ty\n",
    "# each element is of shape (batch size, output vocab size)\n",
    "# therefore if we simply stack all the outputs into 1 tensor\n",
    "# it would be of shape T x N x D\n",
    "# we would like it to be of shape N x T x D\n",
    "\n",
    "def stack_and_transpose(x):\n",
    "  # x is a list of length T, each element is a batch_size x output_vocab_size tensor\n",
    "  x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n",
    "  x = K.permute_dimensions(x, pattern=(1, 0, 2)) # is now batch_size x T x output_vocab_size\n",
    "  return x\n",
    "\n",
    "# make it a layer\n",
    "stacker = Lambda(stack_and_transpose)\n",
    "outputs = stacker(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Keras every operation must be a layer, so make tha above function a layer\n",
    "\n",
    "#### Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDiiDeN6WAtV"
   },
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = Model(\n",
    "  inputs=[\n",
    "    encoder_inputs_placeholder,\n",
    "    decoder_inputs_placeholder,\n",
    "    initial_s, \n",
    "    initial_c,\n",
    "  ],\n",
    "  outputs=outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OR_CNuCcWAwQ"
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "  # both are of shape N x T x K\n",
    "  mask = K.cast(y_true > 0, dtype='float32')\n",
    "  out = mask * y_true * K.log(y_pred)\n",
    "  return -K.sum(out) / K.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PdHOYQNEWA2G"
   },
   "outputs": [],
   "source": [
    "def acc(y_true, y_pred):\n",
    "  # both are of shape N x T x K\n",
    "  targ = K.argmax(y_true, axis=-1)\n",
    "  pred = K.argmax(y_pred, axis=-1)\n",
    "  correct = K.cast(K.equal(targ, pred), dtype='float32')\n",
    "\n",
    "  # 0 is padding, don't include those\n",
    "  mask = K.cast(K.greater(targ, 0), dtype='float32')\n",
    "  n_correct = K.sum(mask * correct)\n",
    "  n_total = K.sum(mask)\n",
    "  return n_correct / n_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_ZsLQtVWA5O"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0509 22:54:09.961210 33168 deprecation_wrapper.py:119] From C:\\Users\\Parth\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss=custom_loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Mb7gVlMEWAzX",
    "outputId": "ee2c4faf-b26d-4fc4-f955-15f372b504d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0509 22:54:10.543700 33168 deprecation.py:323] From C:\\Users\\Parth\\Anaconda3\\envs\\python3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/18\n",
      "16000/16000 [==============================] - 70s 4ms/step - loss: 6.3807 - acc: 0.2434 - val_loss: 6.5619 - val_acc: 0.2129\n",
      "Epoch 2/18\n",
      "16000/16000 [==============================] - 67s 4ms/step - loss: 5.8241 - acc: 0.2599 - val_loss: 6.5597 - val_acc: 0.2395\n",
      "Epoch 3/18\n",
      "16000/16000 [==============================] - 51s 3ms/step - loss: 5.6363 - acc: 0.2805 - val_loss: 6.4843 - val_acc: 0.2451\n",
      "Epoch 4/18\n",
      "16000/16000 [==============================] - 51s 3ms/step - loss: 5.5056 - acc: 0.2841 - val_loss: 6.4200 - val_acc: 0.2471\n",
      "Epoch 5/18\n",
      "16000/16000 [==============================] - 56s 4ms/step - loss: 5.3844 - acc: 0.2904 - val_loss: 6.3143 - val_acc: 0.2552\n",
      "Epoch 6/18\n",
      "16000/16000 [==============================] - 52s 3ms/step - loss: 5.2132 - acc: 0.2957 - val_loss: 5.8843 - val_acc: 0.2621\n",
      "Epoch 7/18\n",
      "16000/16000 [==============================] - 52s 3ms/step - loss: 4.5888 - acc: 0.3439 - val_loss: 5.0774 - val_acc: 0.3257\n",
      "Epoch 8/18\n",
      "16000/16000 [==============================] - 54s 3ms/step - loss: 3.7539 - acc: 0.4242 - val_loss: 4.6207 - val_acc: 0.3718\n",
      "Epoch 9/18\n",
      "16000/16000 [==============================] - 52s 3ms/step - loss: 3.0940 - acc: 0.4880 - val_loss: 4.4425 - val_acc: 0.3995\n",
      "Epoch 10/18\n",
      "16000/16000 [==============================] - 51s 3ms/step - loss: 2.5511 - acc: 0.5408 - val_loss: 4.3398 - val_acc: 0.4224\n",
      "Epoch 11/18\n",
      "16000/16000 [==============================] - 52s 3ms/step - loss: 2.0912 - acc: 0.5922 - val_loss: 4.2537 - val_acc: 0.4372\n",
      "Epoch 12/18\n",
      "16000/16000 [==============================] - 51s 3ms/step - loss: 1.7033 - acc: 0.6395 - val_loss: 4.2000 - val_acc: 0.4540\n",
      "Epoch 13/18\n",
      "16000/16000 [==============================] - 51s 3ms/step - loss: 1.3808 - acc: 0.6911 - val_loss: 4.2273 - val_acc: 0.4572\n",
      "Epoch 14/18\n",
      "16000/16000 [==============================] - 52s 3ms/step - loss: 1.1181 - acc: 0.7379 - val_loss: 4.2088 - val_acc: 0.4645\n",
      "Epoch 15/18\n",
      "16000/16000 [==============================] - 52s 3ms/step - loss: 0.9154 - acc: 0.7800 - val_loss: 4.2342 - val_acc: 0.4665\n",
      "Epoch 16/18\n",
      "16000/16000 [==============================] - 51s 3ms/step - loss: 0.7619 - acc: 0.8116 - val_loss: 4.2160 - val_acc: 0.4754\n",
      "Epoch 17/18\n",
      "16000/16000 [==============================] - 51s 3ms/step - loss: 0.6456 - acc: 0.8341 - val_loss: 4.2569 - val_acc: 0.4791\n",
      "Epoch 18/18\n",
      "16000/16000 [==============================] - 52s 3ms/step - loss: 0.5547 - acc: 0.8533 - val_loss: 4.2843 - val_acc: 0.4823\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "z = np.zeros((len(encoder_inputs), LATENT_DIM_DECODER)) # initial [s, c]\n",
    "r = model.fit(\n",
    "  [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting loss and accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "A4o7I1z5WArn",
    "outputId": "f528a727-6766-4f21-edce-54a7bd950298"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4VFX+x/H3IW0I6SQQIISE3mukqYCLKFjAVVyxgwqiYteV1V377k9311VUVkVFAQtFRXFB7FiwkIQWE1qoCUlIIaSRPuf3xx1kCAmZwGTuzOT7ep55Zu6dc2e+uQyf3Jw59x6ltUYIIYT3aWV2AUIIIZqHBLwQQngpCXghhPBSEvBCCOGlJOCFEMJLScALIYSXkoAXQggvJQEvhBBeSgJeCCG8lK9ZbxwZGanj4uLMenshhPBIycnJ+VrrKEfamhbwcXFxJCUlmfX2QgjhkZRS+x1tK100QgjhpSTghRDCS0nACyGElzKtD74+1dXVZGZmUlFRYXYpbslisRATE4Ofn5/ZpQghPIBbBXxmZibBwcHExcWhlDK7HLeitaagoIDMzEzi4+PNLkcI4QHcqoumoqKCtm3bSrjXQylF27Zt5a8bIYTD3CrgAQn3U5B9I4RoCrcLeCGE8FY7D5Xwwlc72ZFT4pL3c6s+eCGE8CZaa3YcKmFNSg5rUrJJzy1FKWgbFECv6OBmf38JeCGEcCKtNdtzSliTks3qlGz25JXRSsHw+AhuHNWPC/tH0y7Y4pJaJODrcdlll5GRkUFFRQV33303s2bNYu3atTz88MPU1tYSGRnJ119/TWlpKXfeeSdJSUkopXjssce44oorzC5fCOFiWmvSsotZk5LNmpQc9uYboT6ya1tuOjueC/tFExUc4PK63Dbgn/g0lbSsYqe+Zt+OITx2ab9G2y1cuJCIiAjKy8s566yzmDJlCjNnzuT7778nPj6ew4cPA/DUU08RGhpKSkoKAIWFhU6tVwjhvrTWpGYVszolm89SstlXcBSfVopRXdsy89yuXNivPW2DXB/q9tw24M304osvsnLlSgAyMjJYsGABY8aM+X38eUREBABfffUVS5cu/X278PBw1xcrhHAZrTUpB4tsoZ7DgcNGqI/u1pbZY7txQb9oItr4m13m79w24B050m4O69at46uvvuLnn38mMDCQcePGMWjQIHbs2HFSW621DF0UogVIzy1lRXIGq7dmk1lYjm8rxdndI5lzXncm9G1PuBuFuj23DXizFBUVER4eTmBgINu3b+eXX36hsrKS7777jr179/7eRRMREcEFF1zAyy+/zAsvvAAYXTRyFC+EdyirrGF1SjbLEjNI3l+IbyvFuT0iuXt8Dyb0bU9YoHuGuj0J+DomTpzIq6++ysCBA+nVqxcjR44kKiqKBQsWcPnll2O1WmnXrh1ffvklf/3rX7njjjvo378/Pj4+PPbYY1x++eVm/whCiNOktWZTxhGWJ2bw6ZYsyqpq6RrVhocv6s0fh8SY8kXpmZCAryMgIIDPPvus3ucmTZp0wnJQUBCLFi1yRVlCiGZ0uKyKjzZmsjwpg52HSmnt58MlAztw1VmdGdYl3GO7YiXghRAtUq1V82N6PssTM/giLYfqWs3gzmH83+UDuGRgB4Itnn/VVgl4IUSLkll4lBVJmaxIyiCrqILwQD+uHxnHVWd1dsnZpa4kAS+E8HqVNbV8kXqI5UkZ/JieD8A53SN5+OI+TOjbngBfH5MrbB4S8EIIr1VYVsWr3+1mWVIGR45W0ymsNXeP78HUYTHEhAeaXV6zcyjglVITgXmAD/CG1vqZOs/HAouAMFubuVrrNU6uVQghHFJRXctb6/fx33XplFXWMKm/8YXp2d0j8WnlmV+Yno5GA14p5QPMByYAmUCiUmqV1jrNrtlfgeVa61eUUn2BNUBcM9QrhBANqrVqPtqYyX++3El2UQXje7fjoUm96dneu/rWHeXIEfxwIF1rvQdAKbUUmALYB7wGQmyPQ4EsZxYphBCnorVm3c48nv1sO9tzShgUE8rzVw1mZNe2ZpdmKkcCvhOQYbecCYyo0+Zx4Aul1J1AG+B8p1Tn5oKCgigtLTW7DCFatK2ZR/i/Ndv5eU8BXdoGMv+aoVw0INpjx647kyMBX99e0nWWrwbe1lo/p5QaBSxRSvXXWltPeCGlZgGzAGJjY0+nXiGEAOBAwVH+9cUOPt2SRUQbf56Y3I+rh8fi7ysT1R3jSMBnAp3tlmM4uQvmZmAigNb6Z6WUBYgEcu0baa0XAAsAEhIS6v6SONFncyEnxYHymiB6AEx6psGnH3roIbp06cLtt98OwOOPP45Siu+//57CwkKqq6t5+umnmTJlSqNvVVpaypQpU+rdbvHixfz73/9GKcXAgQNZsmQJhw4dYvbs2ezZsweAV155hdGjRzvhhxbCuxwuq+Klb3bxzi/78WmlmHNed24d29UrTkxyNkcCPhHooZSKBw4C04Br6rQ5AIwH3lZK9QEsQJ4zC3WFadOmcc899/we8MuXL2ft2rXce++9hISEkJ+fz8iRI5k8eXKjf/5ZLBZWrlx50nZpaWn8/e9/Z/369URGRv5+bfm77rqLsWPHsnLlSmpra6XrR4g6yqtqWbh+L6+u201ZVQ1XndWZe87vSfsQ18yO5IkaDXitdY1Sag7wOcYQyIVa61Sl1JNAktZ6FXA/8LpS6l6M7pvpWutTH6E35hRH2s1lyJAh5ObmkpWVRV5eHuHh4XTo0IF7772X77//nlatWnHw4EEOHTpEdHT0KV9La83DDz980nbffPMNU6dOJTIyEjh+bflvvvmGxYsXA+Dj40NoaGjz/rBCeIhaq+bDZGNkTE5xBef3acdDE3vTo4WOjGkKh8bB28a0r6mz7lG7x2nA2c4tzRxTp07lgw8+ICcnh2nTpvHuu++Sl5dHcnIyfn5+xMXFUVFR0ejrNLSdXENeCMdorfl2Ry7PfLadnYdKGdQ5jHnTBjOihY+MaQr5NqKOadOmsXTpUj744AOmTp1KUVER7dq1w8/Pj2+//Zb9+/c79DoNbTd+/HiWL19OQUEBwO9dNOPHj+eVV14BoLa2luJi505XKIQnyS2u4Ma3Ernp7SSqaqz899qhfHz7aAn3JpKAr6Nfv36UlJTQqVMnOnTowLXXXktSUhIJCQm8++679O7d26HXaWi7fv368cgjjzB27FgGDRrEfffdB8C8efP49ttvGTBgAMOGDSM1NbXZfkYh3Nk32w8xcd4PbNhbwKOX9OXL+8Zy0YAO8pfvaVBn2lV+uhISEnRSUtIJ67Zt20afPn1MqcdTyD4S3qqyppZnPtvOW+v30Ts6mJevGUL3dtLPXpdSKllrneBIW7nYmBDCdOm5pdz1/ibSsouZPjqOuZN6Y/Hzzis8upIE/BlKSUnh+uuvP2FdQEAAv/76q0kVCeE5tNYsT8rg8VVpWPxa8cYNCZzft73ZZXkNtwt4TxtlMmDAADZv3uyS9zKrO02I5lBUXs3DK1NYvTWb0d3a8vxVg2VMu5O5VcBbLBYKCgpo27atR4W8K2itKSgowGKR/wDC8yXvP8xd728mp7iCP0/sxa1jurWoy/i6ilsFfExMDJmZmeTledxJsC5hsViIiYkxuwwhTlutVfPKunSe/2oXHcMsrJg9iqGx4WaX5bXcKuD9/PyIj483uwwhRDPILirn3mWb+WXPYSYP6sjTf+xPiFw/plm5VcALIbzTF6k5/PnDrVTVWPn3lYO4Ymgn6YZ1AQl4IUSzqaiu5R9rtrH45/307xTCi9OG0DUqyOyyWgwJeCFEs9h1qIQ739/E9pwSZp4bzwMX9iLAV8a2u5IEvBDCqbTWvLfhAE9+mkawxZe3Z5zFuF7tzC6rRZKAF0I4zdGqGh78YCurt2Zzbo9InvvTINoFy9Bes0jACyGcIuPwUWYuTmLnoRIemtibW8d0pZWMbTeVBLwQ4oytT8/njvc2ojW8PWM4Y3pGmV2SQAJeCHEGtNYsXL+Pf6zZRreoNrx+QwJd2rYxuyxhIwEvhDgtFdW1PLwyhY82HuTCfu157k+DCQqQSHEn8q8hhGiyrCPlzH4nma2ZRdw3oSdzzusu/e1uSAJeCNEkifsOc9s7yZRX1bLg+mFc0O/UE9AL80jACyEc9u6v+3l8VSox4YG8P3MkPdrLjEvuTAJeCNGoqhorj61K5f0NBxjbM4oXrx5CaGu5UJi7cyjglVITgXmAD/CG1vqZOs8/D5xnWwwE2mmtw5xZqBDCHLklFdz+zkaS9hcye2w3Hrywl1y73UM0GvBKKR9gPjAByAQSlVKrtNZpx9pore+1a38nMKQZahVCuNiWjCPcuiSZI+VVvHT1EC4d1NHskkQTtHKgzXAgXWu9R2tdBSwFppyi/dXA+84oTghhng+TM7nytZ/xaaX48LbREu4eyJEumk5Aht1yJjCivoZKqS5APPDNmZcmhDBDTa2Vf6zZzsL1exnZNYL51wylbVCA2WWJ0+BIwNfX2dbQ7M/TgA+01rX1vpBSs4BZALGxsQ4VKIRwncKyKu54byM/7S5g+ug4Hrm4D34+jvyhL9yRIwGfCXS2W44BshpoOw24o6EX0lovABYAJCQkNPRLQghhgu05xdyyKInc4kr+OXUgf0ro3PhGwq05EvCJQA+lVDxwECPEr6nbSCnVCwgHfnZqhUKIZvdTej6zliQT6O/DsltHMkQmwvYKjf7tpbWuAeYAnwPbgOVa61Sl1JNKqcl2Ta8Glmqt5chcCA/yyeaD3PjWBjqGWfj4jrMl3L2IQ+PgtdZrgDV11j1aZ/lx55UlhGhuWmte/2EP/1izneHxEbx+Q4KcvORl5ExWIVogq1Xz1Oo03lq/j4sHdOC5Pw3C4ifzpXobCXghWpiK6lruX76F1SnZzDg7jr9d3FeuBOmlJOCFaEGKjlYzc0kSG/Ye5pGL+nDLufEoJeHurSTghWghso6Uc+PCDewrKGPetMFMGdzJ7JJEM5OAF6IF2J5TzPSFiZRV1rBoxnBGd480uyThAhLwQni5n3bnc+viZAIDfFg+exR9OoSYXZJwEQl4IbzYp1uyuH/5FmLbBrLopuF0CmttdknChSTghfBSb/ywh6dXb+OsuHBevyGBsEB/s0sSLiYBL4SXsVo1f1+zjTd/3Muk/tE8f9VgGePeQknAC+FFKmtquW/5FlZvzWb66Dj+dklfmX2pBZOAF8JLFJVXM2txEr/uPcxfJvVm1piuMsa9hZOAF8ILZBeVM31hInvyS3nhqsFcNkTGuAsJeCE83vacYma8lUhJRQ1vTR/OOT1kjLswSMAL4cHW/pbDfcs3ExTgy7JbR9KvY6jZJQk3IgEvhAeyWjUvfZPO81/tZFBMKK9dn0B0qMXssoSbkYAXwsOUVdZw//ItrE3N4fIhnfjH5QNkGKSolwS8EB4k4/BRZi5OYuehEv56cR9uPkeuBikaJgEvhIf4KT2fO97bSK1V89aM4YztGWV2ScLNScAL4ea01iz+eT9P/i+N+Mg2vH5DAvGRbcwuS3gACXgh3FhlTS2PfpzKsqQMzu/TjuevGkywReZNFY6RgBfCTeWVVDL7nWSS9xdyx3nduH9CL5laTzSJBLwQbmhr5hFuXZJM4dEqXrp6CJcO6mh2ScIDtXKkkVJqolJqh1IqXSk1t4E2f1JKpSmlUpVS7zm3TCFajk82H+TKV3+mlVJ8eNtoCXdx2ho9gldK+QDzgQlAJpColFqltU6za9MD+Atwtta6UCnVrrkKFsJb1Vo1//x8O699t4fhcRH897qhRAYFmF2W8GCOdNEMB9K11nsAlFJLgSlAml2bmcB8rXUhgNY619mFCuHNisqruXvpJtbtyOPaEbE8dmk//H0d+gNbiAY5EvCdgAy75UxgRJ02PQGUUusBH+BxrfXaui+klJoFzAKIjY09nXqF8Dq780qZuSiJA4eP8vRl/bluZBezSxJewpGAr+9re13P6/QAxgExwA9Kqf5a6yMnbKT1AmABQEJCQt3XEKLF+XZ7Lne9vwk/31a8e8sIRnRta3ZJwos4EvCZQGe75Rggq542v2itq4G9SqkdGIGf6JQqhfBCb/64l6dXp9EnOoQFNwwjJjzQ7JKEl3Gkky8R6KGUildK+QPTgFV12nwMnAeglIrE6LLZ48xChfAWVqvmqf+l8dT/0rigb3s+uG2UhLtoFo0ewWuta5RSc4DPMfrXF2qtU5VSTwJJWutVtucuUEqlAbXAg1rrguYsXAhPVFFdy/0rZM5U4RpKa3O6whMSEnRSUpIp7y2EGYqOVjNzSRIbZM5UcQaUUsla6wRH2sqZrEK4wMEj5UxfuIF9BWXMmzaYKYNlzlTR/CTghWhmaVnFzHh7A0cra1l003BGd5M5U4VrSMAL0YzWp+dz65JkggJ8WXHbKHpHh5hdkmhBJOCFaCafbD7IAyu2EB/ZhrdnDKdjWGuzSxItjAS8EE6mtebV7/bw7NrtjOwawWvXJxDaWq7hLlxPAl4IJ6q1ap74NJXFP+/n0kEd+feVAwnwlQmxhTkk4IVwkorqWu5euonPUw8xa0xX5k7sLRN0CFNJwAvhBIVlVdy8KJFNGUd49JK+3HROvNklCSEBL8SZyjh8lBsXbiDzSDnzrxnKRQM6mF2SEIAEvBBnJCWziBlvJ1Jda+Wdm0cwPD7C7JKE+J0EvBCnad2OXG5/dyPhgf4snTWC7u2CzS5JiBNIwAtxGpYnZfCXj1Lo2T6Yt2ecRfsQi9klCXESCXghmkBrzfxv0/n3Fzs5t0ck/712KMEWGeMu3JMEvBAOslo1T/4vjbd/2sdlgzvyz6mDZN5U4dYk4IVwQFWNlftXbOHTLVncfE48j1zUR8a4C7cnAS9EI0ora7jtnWR+2JXP3Em9uVWu4y48hAS8EKdQUFrJjLcTSc0q5p9TB/KnhM6NbySEm5CAF6IBx05gOniknNeuG8b5fdubXZIQTSIBL0Q9tucUc8ObG6ioruXdW0aQECcnMAnPIwEvRB2J+w5z89uJtPb3YcXs0fSKlhOYhGeSgBfCzpdph5jz3kY6hbdm8U3DiQkPNLskIU6bBLwQNssTM5j70VYGdArlrRnDiWjjb3ZJQpwRh87SUEpNVErtUEqlK6Xm1vP8dKVUnlJqs+12i/NLFaJ5aK3577p0/vzhVs7uHsl7M0dKuAuv0OgRvFLKB5gPTAAygUSl1CqtdVqdpsu01nOaoUYhmo3Vqnl69TYWrt/L5EEd+feVcnaq8B6OdNEMB9K11nsAlFJLgSlA3YAXwqNU1Vh58IMtfLI5ixlnx/G3i/vK2anCqzhyqNIJyLBbzrStq+sKpdRWpdQHSql6zwZRSs1SSiUppZLy8vJOo1whnKOssoZbFifxyeYsHrywF49eIuEuvI8jAV/fp17XWf4UiNNaDwS+AhbV90Ja6wVa6wStdUJUVFTTKhXCSQ6XVXHNG7/y4648nr1iAHec110uPSC8kiNdNJmA/RF5DJBl30BrXWC3+Drw7JmXJoTzZRYe5YaFGzhYWM6r1w3jgn7RZpckRLNx5Ag+EeihlIpXSvkD04BV9g2UUvaTUE4GtjmvRCGcY19+GVNf+Zm8kkqW3DxCwl14vUaP4LXWNUqpOcDngA+wUGudqpR6EkjSWq8C7lJKTQZqgMPA9GasWYgmyy2p4IaFG6isqWX5raPo0yHE7JJES2W1graCT/OfhqS0rtud7hoJCQk6KSnJlPcWLUtxRTVXvfYL+wvKeG/mSAZ3DjO7JOGJtIbqcqgshsoS477C7nFliW25vnUlJ6679AUYNv20ylBKJWutExxpK2eyCq9WUV3LrMVJ7DpUwpvTz5Jwb8m0hpoKqCgybuVHjj+usH9c37LtZq1p/H38AiEgBAKCwWK7D24PAaHH10UPbP6fFwl44cVqrZp7l23mlz2HeeGqwYztKSO3vF5FMRTsgvx0yN95/HFZrhHQtVWn3t7XApYwsIQat8BIiOh2fNkSYgvvkOPhfSzMjz12QdeLo9ynEiGcSGvNo5/8xme/5fC3S/py2ZD6Tt0QHslaC0UZdULcdivNOd5O+UB4HET2gM7D7ULadmsddmKYB4SAn8W0H6s5SMALrzTv6128++sBZo/txs3nxJtdjnCU1sZRdnW50Z1SnGUEd8EuI8zz06EgHWorj29jCYXIntB9PLTtbjyO7AHh8eDbsq8pJAEvvM47v+znha92MXVYDA9N7GV2Od5PaygvhCP74cgB43a0AKorjJA+dqt3uRxqKm2BXmmsP+k8SkC1sh2N94Ru5xkBHtkT2vaANpEgJ6rVSwJeeJU1Kdn87ZPfGN+7Hc9cPkDOUHWW8iO28LYL8UK7x1UlJ7Zv5Qd+rY0+bV+L0fXhGwC+rY37NlEnLvu1rn+5TTsjyCPijWXRJBLwwmv8tDufe5ZuZmhsOC9fMxRfH7kq5ClZrVBdduIwvrLc46FtH+KVRSdu6x8EYV0gLBbizzXuw2KPr2sto5XcgQS88Aq/HSxi1uJkurQN5M0bE2jt72N2Sa5TVgA5W09vPHZ93SFgDPU7FtaxIyG8y4kh3jpcukU8gAS88Hj7C8qY/lYiIRZfFt88nLBAL/9izWqFnC2w60vY9QVkJlFvUPsFnjyML7i93bLd+mPD/wIjjAAPbCsB7gUk4IVHyyup5IaFG6ixWlk6axQdQlubXVLzqCiC3d8agb7rS6MrBQWdhsK4v0CXUdA6wm3HYwtzyCdAeKySimqmv7WB3OJK3p05gu7tgs0uyXm0htxtxwM94xfjLEpLKHQ/H3pcAN3GQ5CcvCUaJgEvPFJlTS23Lklme04Jb9yYwNDYcLNLOnNVZbD3++OhXmSbZ6f9ABh9lxHqMWfJkblwmHxShMeptWruW7aFn3YX8NyVgzivVzuzSzp9BbuP96Xv+9E4gcc/CLqOgzEPQo8JENLR7CqFh5KAFx5Fa80Tn6ayOiWbhy/qzRXDYswuqWmKDsK+H4wj9b0/QNEBY31kTxg+0wj02FEy5ls4hQS88Cgvf5PO4p/3M2tMV2aN6WZ2OY0rOXQ80Pf9AIf3GOtbh0PcOXD2XUafeoRcTkE4nwS88Bjv/XqA577cyeVDOjF3Ym+zy6lfWYER5Pt+MI7Q83cY6wNCIe5sOGumcWJQu37QSk7EEs1LAl54hLW/5fDXj1MY1yuKZ6cOpFUrNxmjXV4I+3863uWSm2qs9w8yulqGXAtx50KHQdCqBZ18JdyCBLxwe6lZRdy1dBODOofx32uH4mf2JQiyt0DKCiPUs7cC2riGSuwI6P83iB8DHYeAj5+5dYoWTwJeuLWjVTXc+f4mwgP9eOOGBAL9TfrIVhQbob5xkRHwPv4QMxzGzTUCvdMw+WJUuB0JeOHWnliVxt78Mt69eQRtg1wcoFpDZiIkL4LUj6D6KLTvD5P+BQOvNL4oFcKNScALt7V6azbLkjK4fVw3RnePdN0bHz0MW5fBxsWQmwZ+bWDAVBg63bg0gFyjRXgICXjhljILjzL3o60M7hzGvRN6Nv8bam2caLRxEaStMk446jgULp0H/a8wru8ihIdxKOCVUhOBeYAP8IbW+pkG2k0FVgBnaa2TnFalaFFqaq3cs3QzWsOL04Y075eqpbmw+T3jaP3wbmM449AbYNiNED2g+d5XCBdoNOCVUj7AfGACkAkkKqVWaa3T6rQLBu4Cfm2OQkXL8dI36STtL+SFqwYT2zbQ+W9gtcKeb4y+9R1rjIt4xY6GsX+GvlOM2YSE8AKOHMEPB9K11nsAlFJLgSlAWp12TwH/BB5waoWiRdmw9zAvfbOLy4d04rIhnZz74mUFkLTQOFovOmBc83zEbBh6I0S5oBtICBdzJOA7ARl2y5nACPsGSqkhQGet9f+UUg0GvFJqFjALIDY2tunVCq9WdLSae5ZuonNEIE9e1t95L1ycBT+9DMlvGSNh4sfChCeg98UytFF4NUcCvr4hA79PH6OUagU8D0xv7IW01guABQAJCQkNzBUmWiKtNX9ZuZXckko+vG00QQFO+P7/8B5YP8/oY7fWwoAr4Zx7oZ2bXuZACCdz5H9RJtDZbjkGyLJbDgb6A+tsM9hHA6uUUpPli1bhqGWJGaxJyeGhib0Z1PkMJ2w+lAY//gd++xBa+cGQ642LeoXHOaVWITyFIwGfCPRQSsUDB4FpwDXHntRaFwG/D1JWSq0DHpBwF45Kzy3hiU/TOLt7W24d0/X0XygzGX54DnasNsauj7oDRs2B4GjnFSuEB2k04LXWNUqpOcDnGMMkF2qtU5VSTwJJWutVzV2k8F4V1bXc+f5mLH6t+M+fBjf9ImJaG9eE+eE52PsdWMKMOUqHzzImkBaiBXOoo1NrvQZYU2fdow20HXfmZYmW4tm129mWXcybNybQPsTi+IZaw861RrBnJkJQe5jwFCTMkJOShLCRM1mFab7dnstb6/cxfXQc4/u0d2wjay2kroQf/mNcmjcsFi7+Dwy+Fvya8AtCiBZAAl6YIre4ggdWbKF3dDBzJzkwqqWmErYshfUvGKNjInvBH18zLiMgl+UVol4S8MLlrFbN/Su2UFZVw9KrR2Lxa2QijAO/wIe3QFEGdBgMV70DvS6WGZGEaIQEvHC5N37cww+78vn7H/vTo/0p+su1hsQ3YO1coyvmug+h23i5mqMQDpKAFy6VklnEvz7fwcR+0Vwz/BRnM1dXwOr7YfM70OMCuPx1aH2G4+OFaGEk4IXLlFXWcNfSTUQGBfDMFQNQDR2JF2XCsusgaxOMfQjGzpXuGCFOgwS8cJnHVqWyr6CM92eOJCzQv/5Ge3+AFdONL1WnvWdcL0YIcVrksEi4xCebD/JBciZzzuvOyK5tT26gNfw8HxZPMU5QmvmNhLsQZ0iO4EWzyzh8lL+u/I2hsWHcPb7HyQ2qjsKndxmTWve+BC57BSwhri9UCC8jAS+aVXWtlbuWbgIF86YNwbfu7EyF+2DpdXDoN/jD3+Cc+6S/XQgnkYAXzWreV7vYdOAIL109hM4RdWZnSv8aPrwZtBWuXQE9JphTpBBeSgJeNAurVfPC17t4+dt0rhwWw6WDOh5/UmvjjNSvn4QGLRSTAAAQKUlEQVSoPjDtHYg4g6tICiHqJQEvnK68qpb7V2xmTUoOU4fF8PQf7WZnqiyFT26HtE+g3+Uw5WXwb2NesUJ4MQl44VTZReXMXJxEalYxj1zUh1vOjT8+3r1gNyy9FvJ3GFd+HH2nnJUqRDOSgBdOs+lAIbOWJFNeVcubNybwh952V4jc+Tl8OBNa+cB1H0G388wrVIgWQgJeOMUnmw/y4AdbaR8SwLu3jKDnsWvMWK3w/b9g3f9B9ADjQmHhXcwtVogWQgJenBGrVfPclzuY/+1uhsdH8Op1w4hoYztLtaYSPrgJtv8PBk6DS18Av9bmFixECyIBL05bWWUN9y3fzOeph7gqoTNPXdYff1/bGHZrLXw00wj3C/8PRt4m/e1CuJgEvDgtB4+Uc8uiJHbkFPO3S/py09lxx79M1RrWPGiMlLngaRh1u7nFCtFCScCLJkveX8itS5KorLby5vSzOK9XuxMbfPcsJL0Jo+8yRsoIIUwhAS+a5KONmcz9MIUOYRaWzkqge7s6E3YkvmF8oTr4WpjwpDlFCiEAB68mqZSaqJTaoZRKV0rNref52UqpFKXUZqXUj0qpvs4vVZip1qp55rPt3Ld8C0O7hPHx7WefHO6pK2H1A9BzIlz6ovS5C2GyRo/glVI+wHxgApAJJCqlVmmt0+yavae1ftXWfjLwH2BiM9QrTFBaWcM9Szfx1bZcrhkRyxOT++FX96Jhe9YZ49w7j4Cpb4GP/HEohNkc+V84HEjXWu8BUEotBaYAvwe81rrYrn0bQDuzSGGejMNHmbk4iV25pTwxuR83jOpy8kxMWZuMM1Qje8A1S8E/sP4XE0K4lCMB3wnIsFvOBEbUbaSUugO4D/AH/uCU6oSpEvcdZvaSZKpqrbw94yzO7RF1cqOC3fDOVGgdYUyK3Trc9YUKIerlSMDX15F60hG61no+MF8pdQ3wV+DGk15IqVnALIDY2FNMuCxcrqrGSkFZJfklVeSVVrAtu4QXvtpJTHggb9yYQLeooJM3Ks6GJZcBGq5fCSEdT24jhDCNIwGfCXS2W44Bsk7RfinwSn1PaK0XAAsAEhISpBunmdXUWjlcVkVuSSX5pZXklVSSX1plu688fl9ayZGj1Sdtf073SOZfM5TQQL+TX7z8CLxzBZQVwPRPIbK7C34iIURTOBLwiUAPpVQ8cBCYBlxj30Ap1UNrvcu2eDGwC9FstNYcOVpNdlEFOcXl5BRVklNUbluuIK/ECO/DR6vQ9fwabePvQ2RwAFFBAXSLCmJk17ZEBgUQFRxAZJC/7T6AmPDWJ/e3A1SXw/vTIH8nXLscOg1r/h9aCNFkjQa81rpGKTUH+BzwARZqrVOVUk8CSVrrVcAcpdT5QDVQSD3dM8IxtVZNfmklOUUVRmAXlZNdXMGhY8vFFeQUVVBZYz1hu1YKooIDiA6x0DkikKFdwn8P7aigAKKC/YkKshAZ7E+g/xmMcKmtMa4vc+AXmPomdJOvW4RwV0rXd4jnAgkJCTopKcmU925uWmtKK2sorqihpKKa4vIaisurKa6ott3bra84tr6GgtJKDpVUUms98d/E36cV7UMD6BDSmuhQi3ELsdAh1EL7UOM+Kijg5PlOnf+Dwao5sOkdmPQvGDGred9PCHESpVSy1jrBkbYyWPk0aa1JzSrm400H+S2riJKKmt+DuqSiGmsjvzcD/X0IsfgR0tqXEIsfkUH+9GwfTAe7AI+2hXdEG//6u0pc7esnjHAf82cJdyE8gAR8Ex0oOMonmw/y8eaD7M4rw89HMaBTKNEhFnq2DybE4ktIa78TwjvY7nFIaz+CLb4nnyjk7n6eDz8+D8NmwHkPm12NEMIBEvAOOFxWxeqtWXy8OYvk/YUADI+L4KZz4rl4QAfCAv1NrrCZbVkGnz8MfSbDxc/JJQiE8BAS8A0or6rly22H+GTTQb7bmUeNVdOzfRB/ntiLyYM6EhPeQs7W3PWlMUl23Llw+evGlHtCCI8gAW+nptbK+t0FfLLpIJ+n5lBWVUt0iIWbz4lnyuBO9OkQ7B594a6SkQjLb4B2fWHae+BnMbsiIUQTtPiA11qzNbOIjzcf5NMt2eSXVhJs8eWSgR25bEgnRsRH0KpVCwr1Y3K3w3tXQlB74xIElhCzKxJCNFGLDHitNTsPlbL2txw+2XyQPfll+Pu04g+923HZkI6M69UOi5+Xd0VUlkJRpu124PjjIxnGffFBaBNpXIIgqF3jryeEcDstJuBLKqpZn17Adztz+W5HHllFFSgFI+IjmDWmK5P6d6j/lHxPZLVCWa4tsO3CuyjDdsuE8sITt1E+ENIJwjpDl1EQGmNM2hERb87PIIQ4Y14b8FprtueUsG5HHut25JK8v5AaqyYowJdzukdy1/goxvVqR3Soh/Yr11TBkf1weI/ttvf446IMqK06sb1/sBHeoZ0hZvjxx6Exxn1wtHyBKoSX8aqAL66oZv2ufNbtyOO7nXnkFFcA0KdDCLec25VxvaIY1iXcc8agV5dD4T67ELe7FWWCtrtcgX+wcbQdPQD6XGILb1uAh3UGS6hpP4YQwhweHfBaa9Kyi41A35FH8oFCaq2aYIsv5/aIZFzPdoztFUX7EJOO0q1WqKkwbtXlxx/XVEB1xcnLpYeOH40X7jX6we21DoeIrsasSYOuNh4fuwW2lfHpQogTeFzAFx2t5od0I9C/25lHbkklAP06hjB7bFfG9WrHkM5hzrsui9ZQUQSluVCaAyWHbPc5x9eVF0JN5cmhXbebxBFtoozAjh9jF+DxEB4PgRHO+ZmEEC2CxwX82z/t4/mvdhJi8eXcnlGM6xnF2J5RtGvqUbrWUJZnC+pDtntbaJ+wLhdqyk/e3tdiDCEMjoaQGGOMuK/dzc8Cvq3BNwD8bPf1Ldtv1zpchiMKIZzG4wJ+akIM5/Roy6CY0zxKr62G1I/hp3mQk3Ly85ZQCIqG4PbQefjxED+2LijaGDZoCZUuESGEW/O4gO8U1ppOYa2bvmFlKWxaYlw0qygDInvBBU9DWBdbiLc37v1O47WFEMINeVzAN1lpLvz6GiS+ARVHIHY0XPRv6HEBtPKQ0TRCCHEavDfg83fBTy/BlqXGl519LoHRd0Pns8yuTAghXML7Aj5jA6yfB9tXg48/DL4GRs2RSaGFEC2OdwS81Qo718JPL8KBn8ESBmMegOGz5DoqQogWy7MDvqYSti4zumLyd0JoLEx8FoZcBwFBZlcnhBCm8syALz8CSQvh11eN8erRA+CKN6HvZeDjmT+SEEI4m+el4cbFsPYvUFUKXc+DP74GXcfJmHQhhKjDoYBXSk0E5gE+wBta62fqPH8fcAtQA+QBN2mt9zu5VkNYLPSaBKPvhA6DmuUthBDCGzQa8EopH2A+MAHIBBKVUqu01ml2zTYBCVrro0qp24B/Alc1R8F0HWfchBBCnJIjZ/oMB9K11nu01lXAUmCKfQOt9bda66O2xV+AGOeWKYQQoqkcCfhOQIbdcqZtXUNuBj47k6KEEEKcOUf64Ov79lLX21Cp64AEYGwDz88CZgHExsY6WKIQQojT4cgRfCbQ2W45Bsiq20gpdT7wCDBZa11Z3wtprRdorRO01glRUVGnU68QQggHORLwiUAPpVS8UsofmAassm+glBoCvIYR7rnOL1MIIURTNRrwWusaYA7wObANWK61TlVKPamUmmxr9i8gCFihlNqslFrVwMsJIYRwEYfGwWut1wBr6qx71O7x+U6uSwghxBmSC6ILIYSXUlrXOyCm+d9YqTzgdM92jQTynViOK0jNruFpNXtavSA1u0pDNXfRWjs0SsW0gD8TSqkkrXWC2XU0hdTsGp5Ws6fVC1KzqzijZumiEUIILyUBL4QQXspTA36B2QWcBqnZNTytZk+rF6RmVznjmj2yD14IIUTjPPUIXgghRCPcOuCVUhOVUjuUUulKqbn1PB+glFpme/5XpVSc66s8oZ7OSqlvlVLblFKpSqm762kzTilVZDvjd7NS6tH6XsuVlFL7lFIptnqS6nleKaVetO3nrUqpoWbUaaull92+26yUKlZK3VOnjen7WCm1UCmVq5T6zW5dhFLqS6XULtt9eAPb3mhrs0spdaPJNf9LKbXd9u++UikV1sC2p/wMubjmx5VSB+3+/S9qYNtT5ouLa15mV+8+pdTmBrZt2n7WWrvlDWP2qN1AV8Af2AL0rdPmduBV2+NpwDKTa+4ADLU9DgZ21lPzOOB/Zu/fOjXtAyJP8fxFGJeAVsBI4Feza7b7jORgjAt2q30MjAGGAr/ZrfsnMNf2eC7wbD3bRQB7bPfhtsfhJtZ8AeBre/xsfTU78hlycc2PAw848Nk5Zb64suY6zz8HPOqM/ezOR/CNTjRiW15ke/wBMF4p8yZn1Vpna6032h6XYFy751TXzvcUU4DF2vALEKaU6mB2UcB4YLdurukhz4DW+nvgcJ3V9p/XRcBl9Wx6IfCl1vqw1roQ+BKY2GyF2qmvZq31F9q4HhW44WQ+DexnRziSL83iVDXb8utPwPvOeC93DnhHJhr5vY3tQ1gEtHVJdY2wdRcNAX6t5+lRSqktSqnPlFL9XFpY/TTwhVIq2XbN/rqaOumLq0yj4f8I7raPAdprrbPBOBgA2tXTxl33NcBNNDyZT2OfIVebY+tWWthAV5i77udzgUNa610NPN+k/ezOAe/IRCMOT0biSkqpIOBD4B6tdXGdpzdidCkMAl4CPnZ1ffU4W2s9FJgE3KGUGlPnebfbz7ZLV08GVtTztDvuY0e53b4GUEo9AtQA7zbQpLHPkCu9AnQDBgPZGF0edbnlfgau5tRH703az+4c8I5MNPJ7G6WULxDK6f255jRKKT+McH9Xa/1R3ee11sVa61Lb4zWAn1Iq0sVl1q0py3afC6zE+PPVnkOTvrjYJGCj1vpQ3SfccR/bHDrWtWW7r2/uBLfb17Yvei8BrtW2juC6HPgMuYzW+pDWulZrbQVeb6AWd9zPvsDlwLKG2jR1P7tzwDc60Yht+dgog6nANw19AF3B1n/2JrBNa/2fBtpEH/ueQCk1HOPfoMB1VZ5UTxulVPCxxxhfqv1Wp9kq4AbbaJqRQNGxrgYTNXik42772I795/VG4JN62nwOXKCUCrd1LVxgW2cKpdRE4CGMyXyONtDGkc+Qy9T5fuiPDdTiSL642vnAdq11Zn1PntZ+dsW3xmfwbfNFGCNRdgOP2NY9ifFhA7Bg/ImeDmwAuppc7zkYf+ZtBTbbbhcBs4HZtjZzgFSMb+1/AUabXHNXWy1bbHUd28/2NStgvu3fIQVIMLnmQIzADrVb51b7GOOXTzZQjXG0eDPG90NfA7ts9xG2tgnAG3bb3mT7TKcDM0yuOR2jr/rY5/nYqLWOwJpTfYZMrHmJ7XO6FSO0O9St2bZ8Ur6YVbNt/dvHPsN2bc9oP8uZrEII4aXcuYtGCCHEGZCAF0IILyUBL4QQXkoCXgghvJQEvBBCeCkJeCGE8FIS8EII4aUk4IUQwkv9P78AvXBlVdNtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['acc'], label='acc')\n",
    "plt.plot(r.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMOQJqGQWtkM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2LkSmo85WxYy"
   },
   "source": [
    "#### Generative Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUHKDC3cWttL"
   },
   "outputs": [],
   "source": [
    "# As with the poetry example, we need to create another model\n",
    "# that can take in the RNN state and previous word as input\n",
    "# and accept a T=1 sequence.\n",
    "\n",
    "# The encoder will be stand-alone\n",
    "# From this we will get our initial decoder hidden state\n",
    "# i.e. h(1), ..., h(Tx)\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_qIAJuvRWtyW"
   },
   "outputs": [],
   "source": [
    "# next we define a T=1 decoder model\n",
    "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2,))\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aqJc3_dUWt1f"
   },
   "outputs": [],
   "source": [
    "# no need to loop over attention steps this time because there is only one step\n",
    "context = one_step_attention(encoder_outputs_as_input, initial_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AAp0YkTmWt5K"
   },
   "outputs": [],
   "source": [
    "# combine context with last word\n",
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JL0lsUheWtwc"
   },
   "outputs": [],
   "source": [
    "# lstm and final dense\n",
    "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
    "decoder_outputs = decoder_dense(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYeoHdrGWtqR"
   },
   "outputs": [],
   "source": [
    "# note: we don't really need the final stack and tranpose\n",
    "# because there's only 1 output\n",
    "# it is already of size N x D\n",
    "# no need to make it 1 x N x D --> N x 1 x D\n",
    "\n",
    "\n",
    "\n",
    "# create the model object\n",
    "decoder_model = Model(\n",
    "  inputs=[\n",
    "    decoder_inputs_single,\n",
    "    encoder_outputs_as_input,\n",
    "    initial_s, \n",
    "    initial_c\n",
    "  ],\n",
    "  outputs=[decoder_outputs, s, c]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0t8TZaMWtnp"
   },
   "outputs": [],
   "source": [
    "# map indexes back into real words\n",
    "# so we can view the results\n",
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCSRUO4jW-7u"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "  # Encode the input as state vectors.\n",
    "  enc_out = encoder_model.predict(input_seq)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1))\n",
    "  \n",
    "  # Populate the first character of target sequence with the start character.\n",
    "  # NOTE: tokenizer lower-cases all words\n",
    "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "  # if we get this we break\n",
    "  eos = word2idx_outputs['<eos>']\n",
    "\n",
    "\n",
    "  # [s, c] will be updated in each loop iteration\n",
    "  s = np.zeros((1, LATENT_DIM_DECODER))\n",
    "  c = np.zeros((1, LATENT_DIM_DECODER))\n",
    "\n",
    "  # Create the translation\n",
    "  output_sentence = []\n",
    "  for _ in range(max_len_target):\n",
    "    o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n",
    "        \n",
    "\n",
    "    # Get next word\n",
    "    idx = np.argmax(o.flatten())\n",
    "\n",
    "    # End sentence of EOS\n",
    "    if eos == idx:\n",
    "      break\n",
    "\n",
    "    word = ''\n",
    "    if idx > 0:\n",
    "      word = idx2word_trans[idx]\n",
    "      output_sentence.append(word)\n",
    "\n",
    "    # Update the decoder input\n",
    "    # which is just the word just generated\n",
    "    target_seq[0, 0] = idx\n",
    "\n",
    "  return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "S0ZjOJDpXCrf",
    "outputId": "af09b73f-081c-428d-e271-e9d654bb708d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Is it poisonous?\n",
      "Predicted translation: es venenoso?\n",
      "Actual translation: Es venenoso? <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: I'll bring lunch.\n",
      "Predicted translation: yo voy a traer almuerzo.\n",
      "Actual translation: Yo voy a traer almuerzo. <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: Please wake up.\n",
      "Predicted translation: despirtese, por favor.\n",
      "Actual translation: Despirtese, por favor. <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: I looked around me.\n",
      "Predicted translation: me hice por m.\n",
      "Actual translation: He mirado a mi alrededor. <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: I'm sick.\n",
      "Predicted translation: estoy enferma.\n",
      "Actual translation: Estoy enferma. <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: I have a pen.\n",
      "Predicted translation: tengo un pluma.\n",
      "Actual translation: Tengo una pluma. <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: Tom described Mary.\n",
      "Predicted translation: tom no era mary.\n",
      "Actual translation: Tom describi a Mary. <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: You're a funny gal.\n",
      "Predicted translation: sos un tipo de es un mentiroso.\n",
      "Actual translation: Eres una nia divertida. <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: He's not home.\n",
      "Predicted translation: l no est en casa.\n",
      "Actual translation: No est en casa. <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: I saw Tom naked.\n",
      "Predicted translation: vi a desnudo.\n",
      "Actual translation: Vi a Toms desnudo. <eos>\n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  # Do some test translations\n",
    "  i = np.random.choice(len(input_texts))\n",
    "  input_seq = encoder_inputs[i:i+1]\n",
    "  translation = decode_sequence(input_seq)\n",
    "  print('-')\n",
    "  print('Input sentence:', input_texts[i])\n",
    "  print('Predicted translation:', translation)\n",
    "  print('Actual translation:', target_texts[i])\n",
    "\n",
    "  ans = input(\"Continue? [Y/n]\")\n",
    "  if ans and ans.lower().startswith('n'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9WU2Kr5VXCzl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AbkMj_ETW_CI"
   },
   "outputs": [],
   "source": [
    "encoder_model.save(       \"Models/Machine_translation_encoder_18eph_T1\",      include_optimizer=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-aH9hx_dW_Fn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parth\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 's0:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'c0:0' shape=(?, 400) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "decoder_model.save(       \"Models/Machine_translation_decoder_18eph_T1\",      include_optimizer=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5kn6_bvKW-_V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
